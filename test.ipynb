{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from random import randint\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch import autocast\n",
    "from diffusion.util import instantiate_from_config\n",
    "from diffusion import ddpm\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "precision = \"autocast\"\n",
    "device = \"cuda\"\n",
    "\n",
    "## JIT compilation of UNet model \n",
    "n_iter = 1\n",
    "batch_size = 1\n",
    "config = \"diffusion/v1-inference.yaml\"\n",
    "config = OmegaConf.load(f\"{config}\")\n",
    "Height = 128\n",
    "Width = 128\n",
    "scale = 7.5 \n",
    "seed = 1245\n",
    "ddim_eta = 0.0\n",
    "small_batch = \"False\"\n",
    "turbo = True\n",
    "from_file = False\n",
    "n_samples = 1\n",
    "unet_bs = 1\n",
    "fixed_code = False\n",
    "n_rows = 1\n",
    "sampler = \"plms\"\n",
    "\n",
    "\n",
    "if seed == None:\n",
    "    seed = randint(0, 1000000)\n",
    "seed_everything(seed)\n",
    "\n",
    "\n",
    "model = instantiate_from_config(config.modelUNet)\n",
    "\n",
    "if device == \"cuda\" and precision == \"autocast\":\n",
    "    modelsd  = torch.load(\"split_model/model1.4_fp16.pth\")\n",
    "else:\n",
    "    modelsd  = torch.load(\"split_model/model1.4_fp32.pth\")\n",
    "\n",
    "\n",
    "# model.model1 = ddpm.DiffusionWrapper(model.unetConfigEncode)\n",
    "# model.model2 = ddpm.DiffusionWrapperOut(model.unetConfigDecode)\n",
    "_, _ = model.load_state_dict(modelsd['state_dict'] , strict=False)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'state_dict': model.state_dict()}\n",
    "torch.save(state, \"split_model/modelFS1.4_fp32_betas.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"disable-hardware-acceleration\": true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"testImages/dog.png\"\n",
    "mask_path = \"testImages/dog_mask.png\"\n",
    "n_iter = 1\n",
    "batch_size = 1\n",
    "Height = 128\n",
    "Width = 128\n",
    "scale = 7.5 \n",
    "seed = 1245\n",
    "ddim_eta = 0.0\n",
    "small_batch = \"False\"\n",
    "turbo = True\n",
    "from_file = False\n",
    "n_samples = 1\n",
    "precision = \"autocast\"\n",
    "outdir = \"outputs/inpaint-samples\"\n",
    "device = \"cuda\"\n",
    "prompt = \"A bear surfing in the ocean\"\n",
    "unet_bs = 1\n",
    "fixed_code = False\n",
    "n_rows = 1\n",
    "sampler = \"plms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1245\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, re\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "from itertools import islice\n",
    "from einops import rearrange\n",
    "from torchvision.utils import make_grid\n",
    "import time\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch import autocast\n",
    "from contextlib import contextmanager, nullcontext\n",
    "from diffusion.util import instantiate_from_config\n",
    "from diffusion.util import split_weighted_subprompts, logger\n",
    "from transformers import logging\n",
    "# from samplers import CompVisDenoiser\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "def chunk(it, size):\n",
    "    it = iter(it)\n",
    "    return iter(lambda: tuple(islice(it, size)), ())\n",
    "\n",
    "\n",
    "def load_model_from_config(ckpt, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    return sd\n",
    "\n",
    "\n",
    "config = \"diffusion/v1-inference.yaml\"\n",
    "DEFAULT_CKPT = \"models/diffusion/stable-diffusion-v1/model.ckpt\"\n",
    "\n",
    "tic = time.time()\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "outpath = outdir\n",
    "grid_count = len(os.listdir(outpath)) - 1\n",
    "\n",
    "if seed == None:\n",
    "    seed = randint(0, 1000000)\n",
    "seed_everything(seed)\n",
    "\n",
    "config = OmegaConf.load(f\"{config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet: Running in eps-prediction mode\n"
     ]
    }
   ],
   "source": [
    "model = instantiate_from_config(config.modelUNet)\n",
    "modelsd  = torch.load(\"split_model/model1.4_fp16_betas.pth\")\n",
    "_, _ = model.load_state_dict(modelsd['state_dict'] , strict=False)\n",
    "model.model1  = torch.jit.load(\"model1_traced.pth\")\n",
    "model.model2 = torch.jit.load(\"model2_traced.pth\")\n",
    "model.model2.eval()\n",
    "model.model1.eval()\n",
    "_ = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/thunder/stable-diffusion/test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thunder/stable-diffusion/test.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/thunder/stable-diffusion/test.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_tensorrt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thunder/stable-diffusion/test.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch_tensorrt\u001b[39m.\u001b[39mcompile()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_tensorrt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "torch_tensorrt.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = instantiate_from_config(config.modelUNet)\n",
    "# modelsd  = torch.load(\"split_model/model1.4_fp16.pth\")\n",
    "# _, _ = model.load_state_dict(modelsd['state_dict'], strict=False)\n",
    "# model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet: Running in eps-prediction mode\n"
     ]
    }
   ],
   "source": [
    "model = instantiate_from_config(config.modelUNet)\n",
    "modelsd  = torch.load(\"split_model/model1.4_fp16_betas.pth\")\n",
    "_, _ = model.load_state_dict(modelsd['state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = {'state_dict': model.state_dict()}\n",
    "# torch.save(state, \"split_model/model1.4_fp16_betas.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JIT model 1\n",
    "model.to(device)\n",
    "inp = torch.rand([1, 4, 64, 64]).to(device), torch.tensor([981]).to(device), torch.rand([1, 77, 768]).to(device)\n",
    "\n",
    "precision_scope = autocast\n",
    "with precision_scope(\"cuda\"):\n",
    "\n",
    "    m = torch.jit.trace(model.model1, inp)\n",
    "    \n",
    "torch.jit.save(m, \"model1_traced.pth\")\n",
    "\n",
    "\n",
    "# JIT model2\n",
    "\n",
    "ten =  [torch.rand([1, 320, 32, 32]).to(device),\n",
    "        torch.rand([1, 320, 32, 32]).to(device),\n",
    "        torch.rand([1, 320, 32, 32]).to(device),\n",
    "        torch.rand([1, 320, 16, 16]).to(device),\n",
    "        torch.rand([1, 640, 16, 16]).to(device),\n",
    "        torch.rand([1, 640, 16, 16]).to(device),\n",
    "        torch.rand([1, 640, 8, 8]).to(device),\n",
    "        torch.rand([1, 1280, 8, 8]).to(device),\n",
    "        torch.rand([1, 1280, 8, 8]).to(device),\n",
    "        torch.rand([1, 1280, 4, 4]).to(device),\n",
    "        torch.rand([1, 1280, 4, 4]).to(device),\n",
    "        torch.rand([1, 1280, 4, 4]).to(device)]\n",
    "inp = (torch.rand([1, 1280, 4, 4]).to(device), torch.rand([1, 1280]).to(device),ten, torch.rand([1, 77, 768]).to(device))\n",
    "\n",
    "precision_scope = autocast\n",
    "with precision_scope(\"cuda\"):\n",
    "\n",
    "    m = torch.jit.trace(model.model2, inp)\n",
    "\n",
    "torch.jit.save(m, \"model2_traced.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFS = instantiate_from_config(config.modelFirstStage)\n",
    "modelFSsd  = torch.load(\"split_model/modelFS1.4_fp16.pth\")\n",
    "_, _ = modelFS.load_state_dict(modelFSsd['state_dict'], strict=False)\n",
    "modelFS.eval()\n",
    "\n",
    "\n",
    "model = instantiate_from_config(config.modelUNet)\n",
    "modelsd  = torch.load(\"split_model/model1.4_fp16.pth\")\n",
    "_, _ = model.load_state_dict(modelsd['state_dict'] , strict=False)\n",
    "model.eval()\n",
    "model.unet_bs = unet_bs\n",
    "model.cdevice = device\n",
    "model.turbo = turbo\n",
    "\n",
    "modelCS = instantiate_from_config(config.modelCondStage)\n",
    "modelCSsd  = torch.load(\"split_model/modelCS1.4_fp16.pth\")\n",
    "_, _ = modelCS.load_state_dict(modelCSsd['state_dict'], strict=False)\n",
    "modelCS.eval()\n",
    "modelCS.cond_stage_model.device = device\n",
    "\n",
    "del modelCSsd\n",
    "del modelFSsd\n",
    "del modelsd\n",
    "\n",
    "\n",
    "if device != \"cpu\" and precision == \"autocast\":\n",
    "    model.half()\n",
    "    # modelFS.half()\n",
    "    modelCS.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_code = None\n",
    "if fixed_code:\n",
    "    start_code = torch.randn([n_samples, C, H // f, W // f], device=device)\n",
    "\n",
    "\n",
    "batch_size = n_samples\n",
    "n_rows = n_rows if n_rows > 0 else batch_size\n",
    "if not from_file:\n",
    "    assert prompt is not None\n",
    "    prompt = prompt\n",
    "    print(f\"Using prompt: {prompt}\")\n",
    "    data = [batch_size * [prompt]]\n",
    "\n",
    "else:\n",
    "    print(f\"reading prompts from {from_file}\")\n",
    "    with open(from_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        print(f\"Using prompt: {text.strip()}\")\n",
    "        data = text.splitlines()\n",
    "        data = batch_size * list(data)\n",
    "        data = list(chunk(sorted(data), batch_size))\n",
    "\n",
    "\n",
    "if precision == \"autocast\" and device != \"cpu\":\n",
    "    precision_scope = autocast\n",
    "else:\n",
    "    precision_scope = nullcontext\n",
    "\n",
    "seeds = \"\"\n",
    "with torch.no_grad():\n",
    "\n",
    "    all_samples = list()\n",
    "    for n in trange(n_iter, desc=\"Sampling\"):\n",
    "        for prompts in tqdm(data, desc=\"data\"):\n",
    "\n",
    "            sample_path = os.path.join(outpath, \"_\".join(re.split(\":| \", prompts[0])))[:150]\n",
    "            os.makedirs(sample_path, exist_ok=True)\n",
    "            base_count = len(os.listdir(sample_path))\n",
    "\n",
    "            with precision_scope(\"cuda\"):\n",
    "                modelCS.to(device)\n",
    "                uc = None\n",
    "                if scale != 1.0:\n",
    "                    uc = modelCS.get_learned_conditioning(batch_size * [\"\"])\n",
    "                if isinstance(prompts, tuple):\n",
    "                    prompts = list(prompts)\n",
    "\n",
    "                subprompts, weights = split_weighted_subprompts(prompts[0])\n",
    "                if len(subprompts) > 1:\n",
    "                    c = torch.zeros_like(uc)\n",
    "                    totalWeight = sum(weights)\n",
    "                    # normalize each \"sub prompt\" and add it\n",
    "                    for i in range(len(subprompts)):\n",
    "                        weight = weights[i]\n",
    "                        # if not skip_normalize:\n",
    "                        weight = weight / totalWeight\n",
    "                        c = torch.add(c, modelCS.get_learned_conditioning(subprompts[i]), alpha=weight)\n",
    "                else:\n",
    "                    c = modelCS.get_learned_conditioning(prompts)\n",
    "\n",
    "                shape = [n_samples, C, H // f, W // f]\n",
    "\n",
    "                if device != \"cpu\":\n",
    "                    mem = torch.cuda.memory_allocated() / 1e6\n",
    "                    modelCS.to(\"cpu\")\n",
    "                    while torch.cuda.memory_allocated() / 1e6 >= mem:\n",
    "                        time.sleep(1)\n",
    "\n",
    "                samples_ddim = model.sample(\n",
    "                    S=ddim_steps,\n",
    "                    conditioning=c,\n",
    "                    seed=seed,\n",
    "                    shape=shape,\n",
    "                    verbose=False,\n",
    "                    unconditional_guidance_scale=scale,\n",
    "                    unconditional_conditioning=uc,\n",
    "                    eta=ddim_eta,\n",
    "                    x_T=start_code,\n",
    "                    sampler = sampler,\n",
    "                )\n",
    "\n",
    "                modelFS.to(device)\n",
    "\n",
    "                print(samples_ddim.shape)\n",
    "                print(\"saving images\")\n",
    "                for i in range(batch_size):\n",
    "\n",
    "                    x_samples_ddim = modelFS.decode_first_stage(samples_ddim[i].unsqueeze(0))\n",
    "                    x_sample = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "                    x_sample = 255.0 * rearrange(x_sample[0].cpu().numpy(), \"c h w -> h w c\")\n",
    "                    Image.fromarray(x_sample.astype(np.uint8)).save(\n",
    "                        os.path.join(sample_path, \"seed_\" + str(seed) + \"_\" + f\"{base_count:05}.{format}\")\n",
    "                    )\n",
    "                    seeds += str(seed) + \",\"\n",
    "                    seed += 1\n",
    "                    base_count += 1\n",
    "\n",
    "                if device != \"cpu\":\n",
    "                    mem = torch.cuda.memory_allocated() / 1e6\n",
    "                    modelFS.to(\"cpu\")\n",
    "                    while torch.cuda.memory_allocated() / 1e6 >= mem:\n",
    "                        time.sleep(1)\n",
    "                del samples_ddim\n",
    "                print(\"memory_final = \", torch.cuda.memory_allocated() / 1e6)\n",
    "\n",
    "toc = time.time()\n",
    "time_taken = (toc - tic) / 60.0\n",
    "\n",
    "print(\n",
    "    (\n",
    "        \"Samples finished in {0:.2f} minutes and exported to \"\n",
    "        + sample_path\n",
    "        + \"\\n Seeds used = \"\n",
    "        + seeds[:-1]\n",
    "    ).format(time_taken)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "704d9a58ec5c24a0c62095b50f860e4c7e0567b4a5b12bbd4dc5f750fc22252d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
